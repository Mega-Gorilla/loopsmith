# MCP Server Settings
MCP_PORT=23100
# MCP_HOST=localhost  # Currently unused (for future extension)
LOG_LEVEL=info

# Evaluator Settings
# Set to true to use mock evaluator (default is production Codex evaluator)
USE_MOCK_EVALUATOR=false

# Evaluation Settings
MAX_ITERATIONS=5
TARGET_SCORE=8.0

# Evaluation Format Settings
# traditional: score-based JSON format (current default)
# simplified: pass/fail with confidence and markdown context
EVALUATION_FORMAT=traditional

# Confidence Tracking (for simplified format)
CONFIDENCE_TRACKING=true

# Evaluation Mode Settings
# flexible: Accept Codex's natural output (recommended)
# strict: Strictly require JSON format (legacy compatibility)
EVALUATION_MODE=flexible

# Prompt Settings
# Default: prompts/evaluation-prompt-filepath-en.txt (English version)
# To use a custom prompt file, set the path here
EVALUATION_PROMPT_PATH=prompts/evaluation-prompt-filepath-en.txt

# Language Settings
# Set to 'en' for English or 'ja' for Japanese
EVALUATION_LANGUAGE=en

# Performance Settings (recommended values)
# Timeout: Default 5 minutes (300000ms), maximum 30 minutes (1800000ms)
CODEX_TIMEOUT=300000  # 5 minutes (recommended)
CODEX_MAX_BUFFER=20971520  # 20MB

# Performance Optimization Settings
# Enable cache (speeds up re-evaluation of the same file)
CODEX_CACHE_ENABLED=true
# Cache TTL (milliseconds, default 1 hour)
CODEX_CACHE_TTL=3600000
# Reduce log output in production
# NODE_ENV=production

# Output Format Settings
# markdown (default, recommended) or json
MCP_OUTPUT_FORMAT=markdown

# Dashboard Settings
# Enable dashboard (default: true)
ENABLE_DASHBOARD=true
# Dashboard port (default: 3000)
DASHBOARD_PORT=3000
# Auto-open browser (default: true)
AUTO_OPEN_BROWSER=true

# Notes:
# - Codex CLI uses its own authentication system
# - Run 'codex login' command for authentication on first use
# - OPENAI_API_KEY environment variable is not required